# 多分类交叉熵损失梯度下降推导

## 1、问题描述

假设模型为单个神经元，单输入，单输出，多分类任务，使用softmax做多分类，则其前向传播过程为：

$$\begin{equation}z_i=wx_i+b\end{equation}$$

$$\begin{equation}\hat{y}_i=\text{softmax}(z_i)\end{equation}$$

其损失为（关于损失函数原理见[分类任务损失函数的原理](../分类任务损失函数的原理/)）：

$$\begin{equation}L_i=- \log \hat{y}_i\end{equation}$$

$$\begin{equation}L=\frac{1}{N} \sum_{i=1}^N L_i\end{equation}$$

符号说明：

* $N$：表示样本数量；
* $x_i$：表示第$i$条样本的输入；
* $y_i$：表示第$i$条样本的期望输出；
* $\hat{y_i}$：表示第$i$条样本的模型输出；
* $z_i$：表示第$i$条样本只经过权重矩阵，未经过激活函数的中间结果；
* $L_i$：表示第$i$条样本的损失；
* $L$：表示所有$N$条样本的损失；
* $w$和$b$：表示权重参数；

## 2、求导

## 3、梯度下降

## 4、总结

## Reference

* [https://www.zhihu.com/question/39523290 : "陈秋"的回答](https://www.zhihu.com/question/39523290)
