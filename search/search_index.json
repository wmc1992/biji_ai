{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u76ee\u5f55 1\u3001NLP\u5de5\u7a0b sklearn\u8ba1\u7b97\u4e0d\u5e73\u8861\u6570\u636e\u7684\u6743\u91cd 2\u3001NLP\u7b97\u6cd5 Batch Norm Layer Norm","title":"Home"},{"location":"#_1","text":"","title":"\u76ee\u5f55"},{"location":"#1nlp","text":"sklearn\u8ba1\u7b97\u4e0d\u5e73\u8861\u6570\u636e\u7684\u6743\u91cd","title":"1\u3001NLP\u5de5\u7a0b"},{"location":"#2nlp","text":"Batch Norm Layer Norm","title":"2\u3001NLP\u7b97\u6cd5"},{"location":"NLP%E5%B7%A5%E7%A8%8B/sklearn%E8%AE%A1%E7%AE%97%E4%B8%8D%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9D%83%E9%87%8D/","text":"sklearn\u8ba1\u7b97\u4e0d\u5e73\u8861\u6570\u636e\u7684\u6743\u91cd \u51fd\u6570 sklearn.utils.class_weight.compute_class_weight \u53ef\u4ee5\u8ba1\u7b97\u4e0d\u5e73\u8861\u6570\u636e\u7684\u6743\u91cd\uff0c\u7ed9\u6570\u636e\u91cf\u8f83\u5c11\u7684\u7c7b\u522b\u4e00\u4e2a\u8f83\u5927\u7684\u6743\u91cd\uff0c\u7ed9\u6570\u636e\u91cf\u8f83\u591a\u7684\u7c7b\u522b\u4e00\u4e2a\u8f83\u5c0f\u7684\u6743\u91cd\u3002 \u6d4b\u8bd5\u4ee3\u7801\u5982\u4e0b\uff1a import numpy as np from sklearn.utils.class_weight import compute_class_weight def calculate_class_weights(data_list): labels = [] for data in data_list: for label in data[\"labels\"]: labels.append(label) class_weight_result = compute_class_weight('balanced', np.unique(labels), np.array(labels)) label2weight = {} for label, weight in zip(np.unique(labels), class_weight_result): label2weight[label] = weight return label2weight def test_calculate_class_weights(): data_list = [ {\"content\": \"\u8fd9\u91cc\u662f\u6587\u672c\", \"labels\": [\"\u7535\u5f71\", \"\u4ed9\u4fa0\"]}, {\"content\": \"\u8fd9\u91cc\u662f\u6587\u672c\", \"labels\": [\"\u7535\u5f71\", \"\u4ed9\u4fa0\"]}, {\"content\": \"\u8fd9\u91cc\u662f\u6587\u672c\", \"labels\": [\"\u7535\u5f71\", \"\u4ed9\u4fa0\"]}, {\"content\": \"\u8fd9\u91cc\u662f\u6587\u672c\", \"labels\": [\"\u7535\u5f71\", \"\u4ed9\u4fa0\"]}, {\"content\": \"\u8fd9\u91cc\u662f\u6587\u672c\", \"labels\": [\"\u4f53\u80b2\", ]}, ] label2weight = calculate_class_weights(data_list) for label, weight in label2weight.items(): print(label, weight) if __name__ == \"__main__\": test_calculate_class_weights() \u8f93\u51fa\u7ed3\u679c\u5982\u4e0b\uff1a \u4ed9\u4fa0 0.75 \u4f53\u80b2 3.0 \u7535\u5f71 0.75","title":"sklearn\u8ba1\u7b97\u4e0d\u5e73\u8861\u6570\u636e\u7684\u6743\u91cd"},{"location":"NLP%E5%B7%A5%E7%A8%8B/sklearn%E8%AE%A1%E7%AE%97%E4%B8%8D%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9D%83%E9%87%8D/#sklearn","text":"\u51fd\u6570 sklearn.utils.class_weight.compute_class_weight \u53ef\u4ee5\u8ba1\u7b97\u4e0d\u5e73\u8861\u6570\u636e\u7684\u6743\u91cd\uff0c\u7ed9\u6570\u636e\u91cf\u8f83\u5c11\u7684\u7c7b\u522b\u4e00\u4e2a\u8f83\u5927\u7684\u6743\u91cd\uff0c\u7ed9\u6570\u636e\u91cf\u8f83\u591a\u7684\u7c7b\u522b\u4e00\u4e2a\u8f83\u5c0f\u7684\u6743\u91cd\u3002 \u6d4b\u8bd5\u4ee3\u7801\u5982\u4e0b\uff1a import numpy as np from sklearn.utils.class_weight import compute_class_weight def calculate_class_weights(data_list): labels = [] for data in data_list: for label in data[\"labels\"]: labels.append(label) class_weight_result = compute_class_weight('balanced', np.unique(labels), np.array(labels)) label2weight = {} for label, weight in zip(np.unique(labels), class_weight_result): label2weight[label] = weight return label2weight def test_calculate_class_weights(): data_list = [ {\"content\": \"\u8fd9\u91cc\u662f\u6587\u672c\", \"labels\": [\"\u7535\u5f71\", \"\u4ed9\u4fa0\"]}, {\"content\": \"\u8fd9\u91cc\u662f\u6587\u672c\", \"labels\": [\"\u7535\u5f71\", \"\u4ed9\u4fa0\"]}, {\"content\": \"\u8fd9\u91cc\u662f\u6587\u672c\", \"labels\": [\"\u7535\u5f71\", \"\u4ed9\u4fa0\"]}, {\"content\": \"\u8fd9\u91cc\u662f\u6587\u672c\", \"labels\": [\"\u7535\u5f71\", \"\u4ed9\u4fa0\"]}, {\"content\": \"\u8fd9\u91cc\u662f\u6587\u672c\", \"labels\": [\"\u4f53\u80b2\", ]}, ] label2weight = calculate_class_weights(data_list) for label, weight in label2weight.items(): print(label, weight) if __name__ == \"__main__\": test_calculate_class_weights() \u8f93\u51fa\u7ed3\u679c\u5982\u4e0b\uff1a \u4ed9\u4fa0 0.75 \u4f53\u80b2 3.0 \u7535\u5f71 0.75","title":"sklearn\u8ba1\u7b97\u4e0d\u5e73\u8861\u6570\u636e\u7684\u6743\u91cd"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/","text":"Batch Normalize 1\u3001BN\u5177\u4f53\u7684\u64cd\u4f5c\u6b65\u9aa4 \u5176\u64cd\u4f5c\u6b65\u9aa4\u5206\u4e3a\u4e24\u90e8\u5206\uff1a \u6bcf\u4e2a mini-batch \u5185\u7684\u7279\u5f81\u901a\u8fc7\u51cf\u53bb \\mu \\mu \u9664\u4ee5 \\sigma \\sigma \u7684\u65b9\u5f0f\u5f52\u4e00\u5316\u5230\u6807\u51c6\u6b63\u6001\u5206\u5e03\uff1b \u5bf9\u7ecf\u8fc7\u4e0a\u4e00\u6b65\u9aa4\u7684\u8f93\u51fa\u518d\u8fc7\u4e00\u4e2a\u7ebf\u6027\u53d8\u6362\uff1b \u4ee5\u4e0a\u662f\u6587\u5b57\u5f62\u5f0f\u7684\u8bf4\u660e\uff0c\u4e0b\u9762\u662f\u516c\u5f0f\u5f62\u5f0f\u3002 \u8f93\u5165 \uff1a \u4e00\u4e2a mini-batch \u5185\u7684\u6570\u636e\u4e3a \\{x_1, x_2, ..., x_m \\} \\{x_1, x_2, ..., x_m \\} \uff0c\u5176\u4e2d m m \u662f mini-batch-size\uff1b \u8bb0 x_i^{(j)} x_i^{(j)} \u4e3a\u8be5 mini-batch \u4e2d\u7b2c i i \u6761\u6570\u636e\u7684\u7b2c j j \u4e2a\u7279\u5f81\uff1b \\gamma \\gamma \u548c \\beta \\beta \u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff1b \u8f93\u51fa \uff1a y_i^{(j)} y_i^{(j)} \u4e3a\u8be5 mini-batch \u4e2d\u7b2c i i \u6761\u6570\u636e\u7684\u7b2c j j \u4e2a\u7279\u5f81\u7ecf\u8fc7BN\u540e\u7684\u7ed3\u679c\u3002 \u516c\u5f0f \uff1a \u8be5 mini-batch \u4e2d\u7b2cj\u4e2a\u7279\u5f81\u7684\u5747\u503c\uff1a \\mu_{B}^{(j)} = \\frac{1}{m} \\sum_{i=1}^{m} x_{i}^{(j)} \\mu_{B}^{(j)} = \\frac{1}{m} \\sum_{i=1}^{m} x_{i}^{(j)} \u8be5 mini-batch \u4e2d\u7b2cj\u4e2a\u7279\u5f81\u7684\u65b9\u5dee\uff1a \\sigma_{B}^{(j)2} = \\frac{1}{m} \\sum_{i=1}^{m} (x_i^{(j)} - \\mu_B^{(j)})^2 \\sigma_{B}^{(j)2} = \\frac{1}{m} \\sum_{i=1}^{m} (x_i^{(j)} - \\mu_B^{(j)})^2 \u51cf\u53bb\u5747\u503c\uff0c\u9664\u4e0a\u6807\u51c6\u5316\uff0c \\epsilon \\epsilon \u7528\u4e8e\u907f\u514d\u9664\u6570\u4e3a0\uff1a \\hat{x}_i^{(j)} = \\frac{x_i^{(j)} - \\mu_B^{(j)}}{\\sqrt{\\sigma_B^{(j)2} + \\epsilon}} \\hat{x}_i^{(j)} = \\frac{x_i^{(j)} - \\mu_B^{(j)}}{\\sqrt{\\sigma_B^{(j)2} + \\epsilon}} \u7ecf\u8fc7BN\u540e\u7684\u6700\u7ec8\u8f93\u51fa\u7ed3\u679c\uff1a y_i^{(j)} = \\gamma \\hat{x_i^{(j)}} + \\beta y_i^{(j)} = \\gamma \\hat{x_i^{(j)}} + \\beta 2\u3001BN\u662f\u4e3a\u4e86\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898 2.1 ICS\u95ee\u9898\uff08Internal Covariate Shift\uff09 \u5728\u6df1\u5ea6\u6a21\u578b\u4e2d\uff0c\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u7f51\u7edc\u4e2d\u7684\u53c2\u6570\u968f\u7740\u68af\u5ea6\u4e0b\u964d\u5728\u4e0d\u65ad\u66f4\u65b0\u3002\u4e00\u65b9\u9762\uff0c\u5f53\u5e95\u5c42\u7f51\u7edc\u4e2d\u53c2\u6570\u53d1\u751f\u5fae\u5f31\u53d8\u5316\u65f6\uff0c\u7531\u4e8e\u6bcf\u4e00\u5c42\u4e2d\u7684\u7ebf\u6027\u53d8\u6362\u4e0e\u975e\u7ebf\u6027\u6fc0\u6d3b\uff0c\u8fd9\u4e9b\u5fae\u5f31\u53d8\u5316\u968f\u7740\u7f51\u7edc\u5c42\u6570\u7684\u52a0\u6df1\u800c\u88ab\u52a0\u5927\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u53c2\u6570\u7684\u53d8\u5316\u5bfc\u81f4\u6bcf\u4e00\u5c42\u7684\u8f93\u5165\u5206\u5e03\u4f1a\u53d1\u751f\u53d8\u5316\uff0c\u8fdb\u800c\u4e0a\u5c42\u7684\u7f51\u7edc\u9700\u8981\u4e0d\u505c\u7684\u53bb\u9002\u5e94\u8fd9\u4e9b\u5206\u5e03\u7684\u53d8\u5316\uff0c\u4f7f\u7684\u6a21\u578b\u8bad\u7ec3\u53d8\u5f97\u56f0\u96be\u3002\u8fd9\u4e00\u73b0\u8c61\u5c31\u662fICS\u95ee\u9898\u3002 2.2 ICS\u4f1a\u5bfc\u81f4\u7684\u95ee\u9898 \u7531\u4e8e\u4e0b\u5c42\u7f51\u7edc\u7684\u8f93\u51fa\u6570\u636e\u5206\u5e03\u5728\u4e0d\u65ad\u53d8\u5316\uff0c\u4e0a\u5c42\u7f51\u7edc\u5c31\u9700\u8981\u4e0d\u505c\u8c03\u6574\u6765\u9002\u5e94\u8fd9\u4e2a\u53d8\u5316\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u7f51\u7edc\u5b66\u4e60\u901f\u5ea6\u7684\u964d\u4f4e\uff1b \u968f\u7740\u6a21\u578b\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u6a21\u578b\u7684\u53c2\u6570 W W \u4f1a\u53d8\u5927\uff0c\u5219\u6bcf\u5c42\u7684\u8f93\u51fa \\text{Output} = W * \\text{Input} + b \\text{Output} = W * \\text{Input} + b \u4e5f\u4f1a\u53d8\u5927\uff0c\u5f53\u4f7f\u7528\u9971\u548c\u6fc0\u6d3b\u51fd\u6570\u65f6\uff0c\u5c31\u5bb9\u6613\u9677\u5165\u68af\u5ea6\u9971\u548c\u533a\uff0c\u6b64\u65f6\u7684\u68af\u5ea6\u5c31\u4f1a\u5f88\u5c0f\u751a\u81f3\u4e8e\u63a5\u8fd10. 3\u3001\u5728BN\u51fa\u73b0\u524d\uff0c\u662f\u5982\u4f55\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u7684 3.1 \u767d\u5316\u64cd\u4f5c ICS\u4ea7\u751f\u7684\u539f\u56e0\u662f\u7531\u4e8e\u53c2\u6570\u7684\u66f4\u65b0\u5e26\u6765\u7684\u7f51\u7edc\u4e2d\u6bcf\u4e00\u5c42\u8f93\u5165\u503c\u5206\u5e03\u7684\u6539\u53d8\uff0c\u5e76\u4e14\u968f\u7740\u7f51\u7edc\u7684\u52a0\u6df1\u800c\u8d8a\u4e25\u91cd\u3002\u7f13\u89e3ICS\u6700\u76f4\u89c2\u7684\u60f3\u6cd5\u5c31\u662f\uff1a\u56fa\u5b9a\u6bcf\u5c42\u7f51\u7edc\u8f93\u5165\u503c\u7684\u5206\u5e03\u6765\u7f13\u89e3ICS\u95ee\u9898\u3002 \u767d\u5316\u64cd\u4f5c\uff1a\u7ecf\u8fc7\u53d8\u5316\u64cd\u4f5c\u4e4b\u540e\u4f1a\u5177\u6709\u5982\u4e0b\u4e24\u4e2a\u6027\u8d28\uff1a \u7ecf\u8fc7\u767d\u5316\u540e\uff0c\u5176\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u8f83\u4f4e\uff1b \u7ecf\u8fc7\u767d\u5316\u540e\uff0c\u6240\u6709\u7279\u5f81\u5177\u6709\u76f8\u540c\u7684\u65b9\u5dee\uff1b \u5728BN\u51fa\u73b0\u4e4b\u524d\uff0c\u4e3b\u8981\u662f\u5229\u7528\u767d\u5316\u64cd\u4f5c\u6765\u7f13\u89e3ICS\u95ee\u9898\uff1a\u4e3b\u8981\u662fPCA\u767d\u5316\u548cZCA\u767d\u5316\u3002 3.2 \u767d\u5316\u64cd\u4f5c\u7684\u7f3a\u70b9 \u8ba1\u7b97\u6210\u672c\u592a\u9ad8\uff1b \u767d\u5316\u64cd\u4f5c\u5b9e\u9645\u4e0a\u662f\u6539\u53d8\u4e86\u7f51\u7edc\u6bcf\u4e00\u5c42\u7684\u5206\u5e03\uff0c\u6240\u4ee5\u5176\u4e5f\u6539\u53d8\u4e86\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\uff1b 4\u3001BN\u7684\u4f5c\u7528\u4e0e\u4f18\u52bf BN\u5c06\u7f51\u7edc\u6bcf\u4e00\u5c42\u8f93\u5165\u6570\u636e\u7684\u5206\u5e03\u56fa\u5b9a\u5728\u4e00\u5b9a\u7684\u8303\u56f4\u5185\uff0c\u4f7f\u4e0a\u5c42\u7f51\u7edc\u4e0d\u9700\u9891\u7e41\u7684\u53bb\u9002\u5e94\u5e95\u5c42\u7f51\u7edc\uff0c\u52a0\u901f\u4e86\u6a21\u578b\u7684\u5b66\u4e60\u901f\u5ea6\uff1b BN\u80fd\u591f\u4f7f\u6bcf\u5c42\u7f51\u7edc\u7684\u8f93\u5165\u843d\u5728\u9971\u548c\u6fc0\u6d3b\u51fd\u6570\u7684\u975e\u9971\u548c\u533a\uff0c\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff1b BN\u5177\u6709\u4e00\u5b9a\u7684\u6b63\u5219\u5316\u6548\u679c\uff0c\u7531\u4e8e\u6bcf\u4e2a mini-batch \u7684\u5747\u503c\u4e0e\u65b9\u5dee\u4e0d\u5b8c\u5168\u76f8\u540c\uff0c\u76f8\u5f53\u4e8e\u589e\u52a0\u4e86\u968f\u673a\u566a\u58f0\uff0c\u4f7f\u5176\u5177\u6709\u4e00\u5b9a\u7684\u6b63\u5219\u5316\u6548\u679c\uff1b \u7531\u4e8eBN\u64cd\u4f5c\u4e2d\u53ef\u5b66\u4e60\u53c2\u6570 \\gamma \\gamma \u548c \\beta \\beta \u7684\u5b58\u5728\uff0cBN\u7f13\u89e3\u4e86\u4e0a\u8ff0\u6240\u8bf4\u7684\u767d\u5316\u64cd\u4f5c\u7684\u7b2c2\u4e2a\u7f3a\u70b9\uff1b \u7ecf\u8fc7BN\u64cd\u4f5c\u4e4b\u540e\uff0c\u6a21\u578b\u6743\u91cd\u7684\u7f29\u653e\uff08\u6bd4\u5982 W => aW W => aW \uff09\u4f1a\u88ab\u201c\u62b9\u53bb\u201d\uff0c\u8fd9\u4f7f\u6a21\u578b\u5bf9\u7f51\u7edc\u4e2d\u7684\u53c2\u6570\u4e0d\u518d\u8fc7\u5206\u654f\u611f\uff0c\u8bad\u7ec3\u65f6\u66f4\u52a0\u7a33\u5b9a\u3002 Reference https://zhuanlan.zhihu.com/p/34879333 https://www.zhihu.com/question/395811291 https://www.zhihu.com/question/487766088","title":"Batch_Norm"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/#batch-normalize","text":"","title":"Batch Normalize"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/#1bn","text":"\u5176\u64cd\u4f5c\u6b65\u9aa4\u5206\u4e3a\u4e24\u90e8\u5206\uff1a \u6bcf\u4e2a mini-batch \u5185\u7684\u7279\u5f81\u901a\u8fc7\u51cf\u53bb \\mu \\mu \u9664\u4ee5 \\sigma \\sigma \u7684\u65b9\u5f0f\u5f52\u4e00\u5316\u5230\u6807\u51c6\u6b63\u6001\u5206\u5e03\uff1b \u5bf9\u7ecf\u8fc7\u4e0a\u4e00\u6b65\u9aa4\u7684\u8f93\u51fa\u518d\u8fc7\u4e00\u4e2a\u7ebf\u6027\u53d8\u6362\uff1b \u4ee5\u4e0a\u662f\u6587\u5b57\u5f62\u5f0f\u7684\u8bf4\u660e\uff0c\u4e0b\u9762\u662f\u516c\u5f0f\u5f62\u5f0f\u3002 \u8f93\u5165 \uff1a \u4e00\u4e2a mini-batch \u5185\u7684\u6570\u636e\u4e3a \\{x_1, x_2, ..., x_m \\} \\{x_1, x_2, ..., x_m \\} \uff0c\u5176\u4e2d m m \u662f mini-batch-size\uff1b \u8bb0 x_i^{(j)} x_i^{(j)} \u4e3a\u8be5 mini-batch \u4e2d\u7b2c i i \u6761\u6570\u636e\u7684\u7b2c j j \u4e2a\u7279\u5f81\uff1b \\gamma \\gamma \u548c \\beta \\beta \u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff1b \u8f93\u51fa \uff1a y_i^{(j)} y_i^{(j)} \u4e3a\u8be5 mini-batch \u4e2d\u7b2c i i \u6761\u6570\u636e\u7684\u7b2c j j \u4e2a\u7279\u5f81\u7ecf\u8fc7BN\u540e\u7684\u7ed3\u679c\u3002 \u516c\u5f0f \uff1a \u8be5 mini-batch \u4e2d\u7b2cj\u4e2a\u7279\u5f81\u7684\u5747\u503c\uff1a \\mu_{B}^{(j)} = \\frac{1}{m} \\sum_{i=1}^{m} x_{i}^{(j)} \\mu_{B}^{(j)} = \\frac{1}{m} \\sum_{i=1}^{m} x_{i}^{(j)} \u8be5 mini-batch \u4e2d\u7b2cj\u4e2a\u7279\u5f81\u7684\u65b9\u5dee\uff1a \\sigma_{B}^{(j)2} = \\frac{1}{m} \\sum_{i=1}^{m} (x_i^{(j)} - \\mu_B^{(j)})^2 \\sigma_{B}^{(j)2} = \\frac{1}{m} \\sum_{i=1}^{m} (x_i^{(j)} - \\mu_B^{(j)})^2 \u51cf\u53bb\u5747\u503c\uff0c\u9664\u4e0a\u6807\u51c6\u5316\uff0c \\epsilon \\epsilon \u7528\u4e8e\u907f\u514d\u9664\u6570\u4e3a0\uff1a \\hat{x}_i^{(j)} = \\frac{x_i^{(j)} - \\mu_B^{(j)}}{\\sqrt{\\sigma_B^{(j)2} + \\epsilon}} \\hat{x}_i^{(j)} = \\frac{x_i^{(j)} - \\mu_B^{(j)}}{\\sqrt{\\sigma_B^{(j)2} + \\epsilon}} \u7ecf\u8fc7BN\u540e\u7684\u6700\u7ec8\u8f93\u51fa\u7ed3\u679c\uff1a y_i^{(j)} = \\gamma \\hat{x_i^{(j)}} + \\beta y_i^{(j)} = \\gamma \\hat{x_i^{(j)}} + \\beta","title":"1\u3001BN\u5177\u4f53\u7684\u64cd\u4f5c\u6b65\u9aa4"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/#2bn","text":"","title":"2\u3001BN\u662f\u4e3a\u4e86\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/#21-icsinternal-covariate-shift","text":"\u5728\u6df1\u5ea6\u6a21\u578b\u4e2d\uff0c\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u7f51\u7edc\u4e2d\u7684\u53c2\u6570\u968f\u7740\u68af\u5ea6\u4e0b\u964d\u5728\u4e0d\u65ad\u66f4\u65b0\u3002\u4e00\u65b9\u9762\uff0c\u5f53\u5e95\u5c42\u7f51\u7edc\u4e2d\u53c2\u6570\u53d1\u751f\u5fae\u5f31\u53d8\u5316\u65f6\uff0c\u7531\u4e8e\u6bcf\u4e00\u5c42\u4e2d\u7684\u7ebf\u6027\u53d8\u6362\u4e0e\u975e\u7ebf\u6027\u6fc0\u6d3b\uff0c\u8fd9\u4e9b\u5fae\u5f31\u53d8\u5316\u968f\u7740\u7f51\u7edc\u5c42\u6570\u7684\u52a0\u6df1\u800c\u88ab\u52a0\u5927\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u53c2\u6570\u7684\u53d8\u5316\u5bfc\u81f4\u6bcf\u4e00\u5c42\u7684\u8f93\u5165\u5206\u5e03\u4f1a\u53d1\u751f\u53d8\u5316\uff0c\u8fdb\u800c\u4e0a\u5c42\u7684\u7f51\u7edc\u9700\u8981\u4e0d\u505c\u7684\u53bb\u9002\u5e94\u8fd9\u4e9b\u5206\u5e03\u7684\u53d8\u5316\uff0c\u4f7f\u7684\u6a21\u578b\u8bad\u7ec3\u53d8\u5f97\u56f0\u96be\u3002\u8fd9\u4e00\u73b0\u8c61\u5c31\u662fICS\u95ee\u9898\u3002","title":"2.1 ICS\u95ee\u9898\uff08Internal Covariate Shift\uff09"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/#22-ics","text":"\u7531\u4e8e\u4e0b\u5c42\u7f51\u7edc\u7684\u8f93\u51fa\u6570\u636e\u5206\u5e03\u5728\u4e0d\u65ad\u53d8\u5316\uff0c\u4e0a\u5c42\u7f51\u7edc\u5c31\u9700\u8981\u4e0d\u505c\u8c03\u6574\u6765\u9002\u5e94\u8fd9\u4e2a\u53d8\u5316\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u7f51\u7edc\u5b66\u4e60\u901f\u5ea6\u7684\u964d\u4f4e\uff1b \u968f\u7740\u6a21\u578b\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u6a21\u578b\u7684\u53c2\u6570 W W \u4f1a\u53d8\u5927\uff0c\u5219\u6bcf\u5c42\u7684\u8f93\u51fa \\text{Output} = W * \\text{Input} + b \\text{Output} = W * \\text{Input} + b \u4e5f\u4f1a\u53d8\u5927\uff0c\u5f53\u4f7f\u7528\u9971\u548c\u6fc0\u6d3b\u51fd\u6570\u65f6\uff0c\u5c31\u5bb9\u6613\u9677\u5165\u68af\u5ea6\u9971\u548c\u533a\uff0c\u6b64\u65f6\u7684\u68af\u5ea6\u5c31\u4f1a\u5f88\u5c0f\u751a\u81f3\u4e8e\u63a5\u8fd10.","title":"2.2 ICS\u4f1a\u5bfc\u81f4\u7684\u95ee\u9898"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/#3bn","text":"","title":"3\u3001\u5728BN\u51fa\u73b0\u524d\uff0c\u662f\u5982\u4f55\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u7684"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/#31","text":"ICS\u4ea7\u751f\u7684\u539f\u56e0\u662f\u7531\u4e8e\u53c2\u6570\u7684\u66f4\u65b0\u5e26\u6765\u7684\u7f51\u7edc\u4e2d\u6bcf\u4e00\u5c42\u8f93\u5165\u503c\u5206\u5e03\u7684\u6539\u53d8\uff0c\u5e76\u4e14\u968f\u7740\u7f51\u7edc\u7684\u52a0\u6df1\u800c\u8d8a\u4e25\u91cd\u3002\u7f13\u89e3ICS\u6700\u76f4\u89c2\u7684\u60f3\u6cd5\u5c31\u662f\uff1a\u56fa\u5b9a\u6bcf\u5c42\u7f51\u7edc\u8f93\u5165\u503c\u7684\u5206\u5e03\u6765\u7f13\u89e3ICS\u95ee\u9898\u3002 \u767d\u5316\u64cd\u4f5c\uff1a\u7ecf\u8fc7\u53d8\u5316\u64cd\u4f5c\u4e4b\u540e\u4f1a\u5177\u6709\u5982\u4e0b\u4e24\u4e2a\u6027\u8d28\uff1a \u7ecf\u8fc7\u767d\u5316\u540e\uff0c\u5176\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u8f83\u4f4e\uff1b \u7ecf\u8fc7\u767d\u5316\u540e\uff0c\u6240\u6709\u7279\u5f81\u5177\u6709\u76f8\u540c\u7684\u65b9\u5dee\uff1b \u5728BN\u51fa\u73b0\u4e4b\u524d\uff0c\u4e3b\u8981\u662f\u5229\u7528\u767d\u5316\u64cd\u4f5c\u6765\u7f13\u89e3ICS\u95ee\u9898\uff1a\u4e3b\u8981\u662fPCA\u767d\u5316\u548cZCA\u767d\u5316\u3002","title":"3.1 \u767d\u5316\u64cd\u4f5c"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/#32","text":"\u8ba1\u7b97\u6210\u672c\u592a\u9ad8\uff1b \u767d\u5316\u64cd\u4f5c\u5b9e\u9645\u4e0a\u662f\u6539\u53d8\u4e86\u7f51\u7edc\u6bcf\u4e00\u5c42\u7684\u5206\u5e03\uff0c\u6240\u4ee5\u5176\u4e5f\u6539\u53d8\u4e86\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\uff1b","title":"3.2 \u767d\u5316\u64cd\u4f5c\u7684\u7f3a\u70b9"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/#4bn","text":"BN\u5c06\u7f51\u7edc\u6bcf\u4e00\u5c42\u8f93\u5165\u6570\u636e\u7684\u5206\u5e03\u56fa\u5b9a\u5728\u4e00\u5b9a\u7684\u8303\u56f4\u5185\uff0c\u4f7f\u4e0a\u5c42\u7f51\u7edc\u4e0d\u9700\u9891\u7e41\u7684\u53bb\u9002\u5e94\u5e95\u5c42\u7f51\u7edc\uff0c\u52a0\u901f\u4e86\u6a21\u578b\u7684\u5b66\u4e60\u901f\u5ea6\uff1b BN\u80fd\u591f\u4f7f\u6bcf\u5c42\u7f51\u7edc\u7684\u8f93\u5165\u843d\u5728\u9971\u548c\u6fc0\u6d3b\u51fd\u6570\u7684\u975e\u9971\u548c\u533a\uff0c\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff1b BN\u5177\u6709\u4e00\u5b9a\u7684\u6b63\u5219\u5316\u6548\u679c\uff0c\u7531\u4e8e\u6bcf\u4e2a mini-batch \u7684\u5747\u503c\u4e0e\u65b9\u5dee\u4e0d\u5b8c\u5168\u76f8\u540c\uff0c\u76f8\u5f53\u4e8e\u589e\u52a0\u4e86\u968f\u673a\u566a\u58f0\uff0c\u4f7f\u5176\u5177\u6709\u4e00\u5b9a\u7684\u6b63\u5219\u5316\u6548\u679c\uff1b \u7531\u4e8eBN\u64cd\u4f5c\u4e2d\u53ef\u5b66\u4e60\u53c2\u6570 \\gamma \\gamma \u548c \\beta \\beta \u7684\u5b58\u5728\uff0cBN\u7f13\u89e3\u4e86\u4e0a\u8ff0\u6240\u8bf4\u7684\u767d\u5316\u64cd\u4f5c\u7684\u7b2c2\u4e2a\u7f3a\u70b9\uff1b \u7ecf\u8fc7BN\u64cd\u4f5c\u4e4b\u540e\uff0c\u6a21\u578b\u6743\u91cd\u7684\u7f29\u653e\uff08\u6bd4\u5982 W => aW W => aW \uff09\u4f1a\u88ab\u201c\u62b9\u53bb\u201d\uff0c\u8fd9\u4f7f\u6a21\u578b\u5bf9\u7f51\u7edc\u4e2d\u7684\u53c2\u6570\u4e0d\u518d\u8fc7\u5206\u654f\u611f\uff0c\u8bad\u7ec3\u65f6\u66f4\u52a0\u7a33\u5b9a\u3002","title":"4\u3001BN\u7684\u4f5c\u7528\u4e0e\u4f18\u52bf"},{"location":"NLP%E7%AE%97%E6%B3%95/batch_normalize_markdown/#reference","text":"https://zhuanlan.zhihu.com/p/34879333 https://www.zhihu.com/question/395811291 https://www.zhihu.com/question/487766088","title":"Reference"},{"location":"NLP%E7%AE%97%E6%B3%95/layer_normalize_markdown/","text":"Layer Normalize 1\u3001LN\u7684\u5177\u4f53\u64cd\u4f5c\u6b65\u9aa4 \u5176\u64cd\u4f5c\u6b65\u9aa4\u53ef\u5206\u4e3a\u4e09\u90e8\u5206\uff1a \u6c42\u6bcf\u6761\u6570\u636e\u5404\u7279\u5f81\u4e4b\u95f4\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\uff1b \u6bcf\u6761\u6570\u636e\u7684\u6bcf\u4e2a\u7279\u5f81\u51cf\u53bb\u5404\u81ea\u6570\u636e\u7684\u5747\u503c\uff0c\u9664\u4e0a\u5404\u81ea\u6570\u636e\u7684\u6807\u51c6\u5dee\uff1b \u5bf9\u7ecf\u8fc7\u4e0a\u4e00\u6b65\u9aa4\u7684\u8f93\u51fa\u518d\u7ecf\u8fc7\u4e00\u4e2a\u7ebf\u6027\u53d8\u6362\uff1b \u4ee5\u4e0a\u662f\u6587\u5b57\u5f62\u5f0f\u7684\u8bf4\u660e\uff0c\u4ee5\u4e0b\u662f\u516c\u5f0f\u5f62\u5f0f\u3002 \u8f93\u5165 \uff1a \u4e00\u4e2a mini-batch \u7684\u6570\u636e\u5728\u67d0\u5c42\u7f51\u7edc\u7684\u8f93\u51fa\u4e3a \\{\\alpha_1, \\alpha_2, ..., \\alpha_m\\} \\{\\alpha_1, \\alpha_2, ..., \\alpha_m\\} \uff0c\u5176\u4e2d m m \u4e3abatch size\uff1b \u8bb0 \\alpha_i^{(j)} \\alpha_i^{(j)} \u4e3a\u8be5mini-batch\u4e2d\u7b2c i i \u6761\u6570\u636e\u7684\u7b2c j j \u4e2a\u7279\u5f81\uff1b T T \u4e3a\u6bcf\u6761\u6570\u636e\u7684\u7279\u5f81\u6570\uff0c\u6bcf\u6761\u6570\u636e\u7684\u7279\u5f81\u6570\u4e0d\u4e00\u5b9a\u76f8\u540c\uff1b g g \u548c b b \u4e3a\u53ef\u5b66\u4e60\u53c2\u6570\uff1b \u6309\u7167\u4e0a\u8ff0\u5b9a\u4e49\uff0c\u67d0\u5c42\u7f51\u7edc\u7684\u8f93\u51fa\u7684shape\u4e3a [m, T] [m, T] \uff0c m m \u4e3abatch-size\uff0c T T \u4e3a\u6bcf\u6761\u6570\u636e\u7684\u7279\u5f81\u6570\u91cf\uff1b \u8f93\u51fa \uff1a y_i^{(j)} y_i^{(j)} \u4e3a\u8be5 mini-batch \u4e2d\u7b2c i i \u6761\u6570\u636e\u7b2c j j \u4e2a\u7279\u5f81\u7ecf\u8fc7LN\u4e4b\u540e\u7684\u8f93\u51fa\uff1b \u516c\u5f0f \uff1a \u7b2c i i \u6761\u6570\u636e\u5404\u7279\u5f81\u7684\u5747\u503c\uff1a \\mu_i = \\frac{1}{T} \\sum_{j=1}^{T} \\alpha_i^{(j)} \\mu_i = \\frac{1}{T} \\sum_{j=1}^{T} \\alpha_i^{(j)} \u7b2c i i \u6761\u6570\u636e\u5404\u7279\u5f81\u7684\u65b9\u5dee\uff1a \\sigma_i^2 = \\frac{1}{T} \\sum_{j=1}^{T} (\\alpha_i^{(j)} - \\mu_i)^2 \\sigma_i^2 = \\frac{1}{T} \\sum_{j=1}^{T} (\\alpha_i^{(j)} - \\mu_i)^2 \u51cf\u53bb\u5747\u503c\uff0c\u9664\u4e0a\u6807\u51c6\u5316\uff0c \\epsilon \\epsilon \u7528\u4e8e\u907f\u514d\u9664\u6570\u4e3a0\uff1a \\hat{\\alpha_i^{(j)}} = \\frac{\\alpha_i^{(j)} - \\mu_i}{\\sqrt{\\sigma_i^2 + \\epsilon}} \\hat{\\alpha_i^{(j)}} = \\frac{\\alpha_i^{(j)} - \\mu_i}{\\sqrt{\\sigma_i^2 + \\epsilon}} \u7b2c i i \u6761\u6570\u636e\u7b2c j j \u4e2a\u7279\u5f81\u7ecf\u8fc7LN\u540e\u7684\u7ed3\u679c\uff1a y_i^{(j)} = g \\hat{\\alpha_i^{(j)}} + b y_i^{(j)} = g \\hat{\\alpha_i^{(j)}} + b 2\u3001LN \u4e3a\u4e86\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898 \u6df1\u5ea6\u6a21\u578b\u8bad\u7ec3\u65f6\u6240\u9700\u8981\u7684\u8ba1\u7b97\u8d44\u6e90\u975e\u5e38\u5927\uff0c\u60f3\u8981\u51cf\u5c11\u8bad\u7ec3\u6240\u9700\u65f6\u95f4\u7684\u4e00\u4e2a\u65b9\u6cd5\u662f\uff1anormalize the activities of neurons \u589e\u52a0\u8bad\u7ec3\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\uff1b 3\u3001LN \u51fa\u73b0\u4e4b\u524d\u662f\u5982\u4f55\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u7684 LN \u51fa\u73b0\u4e4b\u524d\u901a\u8fc7 BN \u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff1b BN\u7684\u4f18\u70b9\uff1a \u53ef\u4ee5\u89e3\u51b3 \"convariate shift\" \u95ee\u9898\uff0c\u7f29\u77ed\u4e86\u6a21\u578b\u8bad\u7ec3\u6240\u9700\u7684\u65f6\u95f4\uff1b \u80fd\u591f\u4f7f\u9971\u548c\u6fc0\u6d3b\u51fd\u6570\u7684\u8f93\u5165\u843d\u5728\u975e\u9971\u548c\u533a\uff0c\u589e\u52a0\u4e86\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\uff1b BN\u7684\u7f3a\u70b9\uff1a \u5f53 batch size \u7279\u522b\u5c0f\u65f6\uff0c\u8868\u73b0\u4e0d\u597d\uff1b \u5f53\u6bcf\u6761\u6570\u636e\u7684\u957f\u5ea6\u4e0d\u4e00\u81f4\u65f6\uff0c\u6bd4\u5982\u6587\u672c\u6570\u636e\uff0c\u6548\u679c\u4e0d\u597d\uff1b \u5728 RNN \u7f51\u7edc\u4e2d\uff0c\u8868\u73b0\u4e0d\u597d\uff1b 4\u3001LN \u7684\u4f18\u52bf Normalization \u7684\u4f5c\u7528\uff1a\u964d\u4f4e\u4e86\u5bf9\u53c2\u6570\u521d\u59cb\u5316\u7684\u9700\u6c42\uff0c\u5141\u8bb8\u4f7f\u7528\u66f4\u5927\u7684\u5b66\u4e60\u7387\uff0c\u6709\u4e00\u5b9a\u7684\u6b63\u5219\u5316\u4f5c\u7528\u53ef\u6297\u8fc7\u62df\u5408\uff0c\u4f7f\u8bad\u7ec3\u66f4\u52a0\u7a33\u5b9a\u3002 \u5047\u8bbe\u67d0\u4e00\u5c42\u8f93\u51fa\u7684\u4e2d\u95f4\u7ed3\u679c\u4e3a [m, T] [m, T] \uff0c m m \u4e3abatch-size\uff0c T T \u4e3a\u6bcf\u6761\u6570\u636e\u7684\u7279\u5f81\u6570\u91cf\uff0c\u90a3\u4e48\uff1a BN \u662f\u5bf9 m m \u8fd9\u4e2a\u7ef4\u5ea6\u505a\u5f52\u4e00\u5316\uff1b LN \u662f\u5bf9 T T \u8fd9\u4e2a\u7ef4\u5ea6\u505a\u5f52\u4e00\u5316\uff1b \u4f18\u52bf\uff08\u4ee5\u4e0b\u90fd\u6709\u5f85\u8003\u8bc1\uff09\uff1a \u5728 RNN \u7f51\u7edc\u4e2d\uff0c\u8868\u73b0\u8f83\u597d\uff1b \u5728 batch size \u8f83\u5c0f\u7684\u7f51\u7edc\u4e2d\uff0c\u8868\u73b0\u8f83\u597d\uff1b LN \u62b9\u6740\u4e86\u4e0d\u540c\u6837\u672c\u95f4\u7684\u5927\u5c0f\u5173\u7cfb\uff0c\u4fdd\u7559\u4e86\u540c\u4e00\u4e2a\u6837\u672c\u5185\u90e8\u7684\u7279\u5f81\u4e4b\u95f4\u7684\u5927\u5c0f\u5173\u7cfb\uff0c\u8fd9\u5bf9\u4e8e\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u6216NLP\u4efb\u52a1\u6765\u8bf4\u975e\u5e38\u91cd\u8981\uff1b 5\u3001LN\u6548\u679c\u6d4b\u8bd5\u4ee3\u7801 import torch import torch.nn as nn # NLP\u4f8b\u5b50\uff0c\u4e00\u822c\u5728NLP\u4efb\u52a1\u4e2d\uff0c\u5176\u7ef4\u5ea6\u4e3a[batch_size, seq_len, hidden_dim]\uff0cLayerNorm\u64cd\u4f5c\u4ec5\u5bf9\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u505a\u64cd\u4f5c batch, sentence_length, hidden_dim = 20, 5, 10 embedding = torch.randn(batch, sentence_length, hidden_dim) print(\"LayerNorm\u524d, \u5747\u503c: \") mean_result = embedding.mean((-1)) # \u8ba1\u7b97\u7ef4\u5ea6 hidden_dim \u7684\u5747\u503c print([f\"%.2f\" % float(y) for x in mean_result.detach().numpy().tolist() for y in x][:20], \"...\") print(\"LayerNorm\u524d, \u65b9\u5dee: \") var_result = embedding.var((-1)) # \u8ba1\u7b97\u7ef4\u5ea6 hidden_dim \u7684\u65b9\u5dee print([f\"%.2f\" % float(y) for x in var_result.detach().numpy().tolist() for y in x][:20], \"...\") # \u8be5LayerNorm\u5c42\u7684input\u7684\u7ef4\u5ea6\u4e3a[*, hidden_dim]\uff0c\u5176\u4ec5\u5bf9\u521d\u59cb\u5316\u65f6\u7ed9\u5b9a\u7684hidden_dim\u8fd9\u4e2a\u7ef4\u5ea6\u505a\u5f52\u4e00\u5316 layer_norm = nn.LayerNorm(hidden_dim) embedding = layer_norm(embedding) print(\"LayerNorm\u540e, \u5747\u503c: \") mean_result = embedding.mean((-1)) # \u8ba1\u7b97\u7ef4\u5ea6 hidden_dim \u7684\u5747\u503c print([f\"%.2f\" % float(y) for x in mean_result.detach().numpy().tolist() for y in x][:20], \"...\") print(\"LayerNorm\u540e, \u65b9\u5dee: \") var_result = embedding.var((-1)) # \u8ba1\u7b97\u7ef4\u5ea6 hidden_dim \u7684\u65b9\u5dee print([f\"%.2f\" % float(y) for x in var_result.detach().numpy().tolist() for y in x][:20], \"...\") \u8f93\u51fa\u7ed3\u679c\uff1a LayerNorm\u524d, \u5747\u503c: ['0.23', '0.23', '0.18', '-0.06', '-0.45', '-0.24', '0.34', '0.23', '-0.47', '-0.44', '0.12', '-0.26', '-0.37', '0.33', '-0.50', '0.11', '0.14', '0.37', '-0.12', '0.31'] ... LayerNorm\u524d, \u65b9\u5dee: ['1.34', '0.51', '1.16', '0.90', '0.17', '0.50', '0.56', '0.61', '0.70', '1.06', '0.85', '1.26', '1.34', '1.45', '1.52', '0.75', '0.63', '1.37', '1.34', '1.51'] ... LayerNorm\u540e, \u5747\u503c: ['0.00', '-0.00', '-0.00', '0.00', '0.00', '-0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '-0.00', '0.00', '0.00', '-0.00', '-0.00', '-0.00', '0.00'] ... LayerNorm\u540e, \u65b9\u5dee: ['1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11'] ... \u53ef\u4ee5\u770b\u51fa\uff0c\u7ecf\u8fc7\u5f52\u4e00\u5316\u4e4b\u540e\uff0c\u5176\u5747\u503c\u4e3a0\uff0c\u65b9\u5dee\u4e3a1.11\uff08\u8fd9\u91cc\u4e3a\u4ec0\u4e48\u662f1.11\uff0c\u800c\u4e0d\u662f1\uff0c\u8fd8\u6ca1\u641e\u6e05\u695a\uff09\uff1b","title":"Layer_Norm"},{"location":"NLP%E7%AE%97%E6%B3%95/layer_normalize_markdown/#layer-normalize","text":"","title":"Layer Normalize"},{"location":"NLP%E7%AE%97%E6%B3%95/layer_normalize_markdown/#1ln","text":"\u5176\u64cd\u4f5c\u6b65\u9aa4\u53ef\u5206\u4e3a\u4e09\u90e8\u5206\uff1a \u6c42\u6bcf\u6761\u6570\u636e\u5404\u7279\u5f81\u4e4b\u95f4\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\uff1b \u6bcf\u6761\u6570\u636e\u7684\u6bcf\u4e2a\u7279\u5f81\u51cf\u53bb\u5404\u81ea\u6570\u636e\u7684\u5747\u503c\uff0c\u9664\u4e0a\u5404\u81ea\u6570\u636e\u7684\u6807\u51c6\u5dee\uff1b \u5bf9\u7ecf\u8fc7\u4e0a\u4e00\u6b65\u9aa4\u7684\u8f93\u51fa\u518d\u7ecf\u8fc7\u4e00\u4e2a\u7ebf\u6027\u53d8\u6362\uff1b \u4ee5\u4e0a\u662f\u6587\u5b57\u5f62\u5f0f\u7684\u8bf4\u660e\uff0c\u4ee5\u4e0b\u662f\u516c\u5f0f\u5f62\u5f0f\u3002 \u8f93\u5165 \uff1a \u4e00\u4e2a mini-batch \u7684\u6570\u636e\u5728\u67d0\u5c42\u7f51\u7edc\u7684\u8f93\u51fa\u4e3a \\{\\alpha_1, \\alpha_2, ..., \\alpha_m\\} \\{\\alpha_1, \\alpha_2, ..., \\alpha_m\\} \uff0c\u5176\u4e2d m m \u4e3abatch size\uff1b \u8bb0 \\alpha_i^{(j)} \\alpha_i^{(j)} \u4e3a\u8be5mini-batch\u4e2d\u7b2c i i \u6761\u6570\u636e\u7684\u7b2c j j \u4e2a\u7279\u5f81\uff1b T T \u4e3a\u6bcf\u6761\u6570\u636e\u7684\u7279\u5f81\u6570\uff0c\u6bcf\u6761\u6570\u636e\u7684\u7279\u5f81\u6570\u4e0d\u4e00\u5b9a\u76f8\u540c\uff1b g g \u548c b b \u4e3a\u53ef\u5b66\u4e60\u53c2\u6570\uff1b \u6309\u7167\u4e0a\u8ff0\u5b9a\u4e49\uff0c\u67d0\u5c42\u7f51\u7edc\u7684\u8f93\u51fa\u7684shape\u4e3a [m, T] [m, T] \uff0c m m \u4e3abatch-size\uff0c T T \u4e3a\u6bcf\u6761\u6570\u636e\u7684\u7279\u5f81\u6570\u91cf\uff1b \u8f93\u51fa \uff1a y_i^{(j)} y_i^{(j)} \u4e3a\u8be5 mini-batch \u4e2d\u7b2c i i \u6761\u6570\u636e\u7b2c j j \u4e2a\u7279\u5f81\u7ecf\u8fc7LN\u4e4b\u540e\u7684\u8f93\u51fa\uff1b \u516c\u5f0f \uff1a \u7b2c i i \u6761\u6570\u636e\u5404\u7279\u5f81\u7684\u5747\u503c\uff1a \\mu_i = \\frac{1}{T} \\sum_{j=1}^{T} \\alpha_i^{(j)} \\mu_i = \\frac{1}{T} \\sum_{j=1}^{T} \\alpha_i^{(j)} \u7b2c i i \u6761\u6570\u636e\u5404\u7279\u5f81\u7684\u65b9\u5dee\uff1a \\sigma_i^2 = \\frac{1}{T} \\sum_{j=1}^{T} (\\alpha_i^{(j)} - \\mu_i)^2 \\sigma_i^2 = \\frac{1}{T} \\sum_{j=1}^{T} (\\alpha_i^{(j)} - \\mu_i)^2 \u51cf\u53bb\u5747\u503c\uff0c\u9664\u4e0a\u6807\u51c6\u5316\uff0c \\epsilon \\epsilon \u7528\u4e8e\u907f\u514d\u9664\u6570\u4e3a0\uff1a \\hat{\\alpha_i^{(j)}} = \\frac{\\alpha_i^{(j)} - \\mu_i}{\\sqrt{\\sigma_i^2 + \\epsilon}} \\hat{\\alpha_i^{(j)}} = \\frac{\\alpha_i^{(j)} - \\mu_i}{\\sqrt{\\sigma_i^2 + \\epsilon}} \u7b2c i i \u6761\u6570\u636e\u7b2c j j \u4e2a\u7279\u5f81\u7ecf\u8fc7LN\u540e\u7684\u7ed3\u679c\uff1a y_i^{(j)} = g \\hat{\\alpha_i^{(j)}} + b y_i^{(j)} = g \\hat{\\alpha_i^{(j)}} + b","title":"1\u3001LN\u7684\u5177\u4f53\u64cd\u4f5c\u6b65\u9aa4"},{"location":"NLP%E7%AE%97%E6%B3%95/layer_normalize_markdown/#2ln","text":"\u6df1\u5ea6\u6a21\u578b\u8bad\u7ec3\u65f6\u6240\u9700\u8981\u7684\u8ba1\u7b97\u8d44\u6e90\u975e\u5e38\u5927\uff0c\u60f3\u8981\u51cf\u5c11\u8bad\u7ec3\u6240\u9700\u65f6\u95f4\u7684\u4e00\u4e2a\u65b9\u6cd5\u662f\uff1anormalize the activities of neurons \u589e\u52a0\u8bad\u7ec3\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\uff1b","title":"2\u3001LN \u4e3a\u4e86\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898"},{"location":"NLP%E7%AE%97%E6%B3%95/layer_normalize_markdown/#3ln","text":"LN \u51fa\u73b0\u4e4b\u524d\u901a\u8fc7 BN \u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff1b BN\u7684\u4f18\u70b9\uff1a \u53ef\u4ee5\u89e3\u51b3 \"convariate shift\" \u95ee\u9898\uff0c\u7f29\u77ed\u4e86\u6a21\u578b\u8bad\u7ec3\u6240\u9700\u7684\u65f6\u95f4\uff1b \u80fd\u591f\u4f7f\u9971\u548c\u6fc0\u6d3b\u51fd\u6570\u7684\u8f93\u5165\u843d\u5728\u975e\u9971\u548c\u533a\uff0c\u589e\u52a0\u4e86\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\uff1b BN\u7684\u7f3a\u70b9\uff1a \u5f53 batch size \u7279\u522b\u5c0f\u65f6\uff0c\u8868\u73b0\u4e0d\u597d\uff1b \u5f53\u6bcf\u6761\u6570\u636e\u7684\u957f\u5ea6\u4e0d\u4e00\u81f4\u65f6\uff0c\u6bd4\u5982\u6587\u672c\u6570\u636e\uff0c\u6548\u679c\u4e0d\u597d\uff1b \u5728 RNN \u7f51\u7edc\u4e2d\uff0c\u8868\u73b0\u4e0d\u597d\uff1b","title":"3\u3001LN \u51fa\u73b0\u4e4b\u524d\u662f\u5982\u4f55\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u7684"},{"location":"NLP%E7%AE%97%E6%B3%95/layer_normalize_markdown/#4ln","text":"Normalization \u7684\u4f5c\u7528\uff1a\u964d\u4f4e\u4e86\u5bf9\u53c2\u6570\u521d\u59cb\u5316\u7684\u9700\u6c42\uff0c\u5141\u8bb8\u4f7f\u7528\u66f4\u5927\u7684\u5b66\u4e60\u7387\uff0c\u6709\u4e00\u5b9a\u7684\u6b63\u5219\u5316\u4f5c\u7528\u53ef\u6297\u8fc7\u62df\u5408\uff0c\u4f7f\u8bad\u7ec3\u66f4\u52a0\u7a33\u5b9a\u3002 \u5047\u8bbe\u67d0\u4e00\u5c42\u8f93\u51fa\u7684\u4e2d\u95f4\u7ed3\u679c\u4e3a [m, T] [m, T] \uff0c m m \u4e3abatch-size\uff0c T T \u4e3a\u6bcf\u6761\u6570\u636e\u7684\u7279\u5f81\u6570\u91cf\uff0c\u90a3\u4e48\uff1a BN \u662f\u5bf9 m m \u8fd9\u4e2a\u7ef4\u5ea6\u505a\u5f52\u4e00\u5316\uff1b LN \u662f\u5bf9 T T \u8fd9\u4e2a\u7ef4\u5ea6\u505a\u5f52\u4e00\u5316\uff1b \u4f18\u52bf\uff08\u4ee5\u4e0b\u90fd\u6709\u5f85\u8003\u8bc1\uff09\uff1a \u5728 RNN \u7f51\u7edc\u4e2d\uff0c\u8868\u73b0\u8f83\u597d\uff1b \u5728 batch size \u8f83\u5c0f\u7684\u7f51\u7edc\u4e2d\uff0c\u8868\u73b0\u8f83\u597d\uff1b LN \u62b9\u6740\u4e86\u4e0d\u540c\u6837\u672c\u95f4\u7684\u5927\u5c0f\u5173\u7cfb\uff0c\u4fdd\u7559\u4e86\u540c\u4e00\u4e2a\u6837\u672c\u5185\u90e8\u7684\u7279\u5f81\u4e4b\u95f4\u7684\u5927\u5c0f\u5173\u7cfb\uff0c\u8fd9\u5bf9\u4e8e\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u6216NLP\u4efb\u52a1\u6765\u8bf4\u975e\u5e38\u91cd\u8981\uff1b","title":"4\u3001LN \u7684\u4f18\u52bf"},{"location":"NLP%E7%AE%97%E6%B3%95/layer_normalize_markdown/#5ln","text":"import torch import torch.nn as nn # NLP\u4f8b\u5b50\uff0c\u4e00\u822c\u5728NLP\u4efb\u52a1\u4e2d\uff0c\u5176\u7ef4\u5ea6\u4e3a[batch_size, seq_len, hidden_dim]\uff0cLayerNorm\u64cd\u4f5c\u4ec5\u5bf9\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u505a\u64cd\u4f5c batch, sentence_length, hidden_dim = 20, 5, 10 embedding = torch.randn(batch, sentence_length, hidden_dim) print(\"LayerNorm\u524d, \u5747\u503c: \") mean_result = embedding.mean((-1)) # \u8ba1\u7b97\u7ef4\u5ea6 hidden_dim \u7684\u5747\u503c print([f\"%.2f\" % float(y) for x in mean_result.detach().numpy().tolist() for y in x][:20], \"...\") print(\"LayerNorm\u524d, \u65b9\u5dee: \") var_result = embedding.var((-1)) # \u8ba1\u7b97\u7ef4\u5ea6 hidden_dim \u7684\u65b9\u5dee print([f\"%.2f\" % float(y) for x in var_result.detach().numpy().tolist() for y in x][:20], \"...\") # \u8be5LayerNorm\u5c42\u7684input\u7684\u7ef4\u5ea6\u4e3a[*, hidden_dim]\uff0c\u5176\u4ec5\u5bf9\u521d\u59cb\u5316\u65f6\u7ed9\u5b9a\u7684hidden_dim\u8fd9\u4e2a\u7ef4\u5ea6\u505a\u5f52\u4e00\u5316 layer_norm = nn.LayerNorm(hidden_dim) embedding = layer_norm(embedding) print(\"LayerNorm\u540e, \u5747\u503c: \") mean_result = embedding.mean((-1)) # \u8ba1\u7b97\u7ef4\u5ea6 hidden_dim \u7684\u5747\u503c print([f\"%.2f\" % float(y) for x in mean_result.detach().numpy().tolist() for y in x][:20], \"...\") print(\"LayerNorm\u540e, \u65b9\u5dee: \") var_result = embedding.var((-1)) # \u8ba1\u7b97\u7ef4\u5ea6 hidden_dim \u7684\u65b9\u5dee print([f\"%.2f\" % float(y) for x in var_result.detach().numpy().tolist() for y in x][:20], \"...\") \u8f93\u51fa\u7ed3\u679c\uff1a LayerNorm\u524d, \u5747\u503c: ['0.23', '0.23', '0.18', '-0.06', '-0.45', '-0.24', '0.34', '0.23', '-0.47', '-0.44', '0.12', '-0.26', '-0.37', '0.33', '-0.50', '0.11', '0.14', '0.37', '-0.12', '0.31'] ... LayerNorm\u524d, \u65b9\u5dee: ['1.34', '0.51', '1.16', '0.90', '0.17', '0.50', '0.56', '0.61', '0.70', '1.06', '0.85', '1.26', '1.34', '1.45', '1.52', '0.75', '0.63', '1.37', '1.34', '1.51'] ... LayerNorm\u540e, \u5747\u503c: ['0.00', '-0.00', '-0.00', '0.00', '0.00', '-0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '-0.00', '0.00', '0.00', '-0.00', '-0.00', '-0.00', '0.00'] ... LayerNorm\u540e, \u65b9\u5dee: ['1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11', '1.11'] ... \u53ef\u4ee5\u770b\u51fa\uff0c\u7ecf\u8fc7\u5f52\u4e00\u5316\u4e4b\u540e\uff0c\u5176\u5747\u503c\u4e3a0\uff0c\u65b9\u5dee\u4e3a1.11\uff08\u8fd9\u91cc\u4e3a\u4ec0\u4e48\u662f1.11\uff0c\u800c\u4e0d\u662f1\uff0c\u8fd8\u6ca1\u641e\u6e05\u695a\uff09\uff1b","title":"5\u3001LN\u6548\u679c\u6d4b\u8bd5\u4ee3\u7801"}]}